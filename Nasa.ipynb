{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "    \n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "# load up other dependencies\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_files = glob.glob('*.gz')\n",
    "raw_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = spark.read.text(raw_data_files)\n",
    "base_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df_rdd = base_df.rdd\n",
    "type(base_df_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_df_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print((base_df.count(), len(base_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encontrando nome dos hots\n",
    "host_pattern = r'(^\\S+\\.[\\S+\\.]+\\S+)\\s'\n",
    "hosts = [re.search(host_pattern, item).group(1)\n",
    "           if re.search(host_pattern, item)\n",
    "           else 'Nope'\n",
    "           for item in sample_logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df_rdd.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extraindo as datas\n",
    "ts_pattern = r'\\[(\\d{2}/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]'\n",
    "\n",
    "timestamps = [re.search(ts_pattern, item).group(1) for item in sample_logs]\n",
    "\n",
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extraindo REQUESTS\n",
    "method_uri_protocol_pattern = r'\\\"(\\S+)\\s(\\S+)\\s*(\\S*)\\\"'\n",
    "\n",
    "method_uri_protocol = [re.search(method_uri_protocol_pattern, item).groups()\n",
    "\n",
    "               if re.search(method_uri_protocol_pattern, item)\n",
    "\n",
    "               else 'Nope'\n",
    "\n",
    "              for item in sample_logs]\n",
    "\n",
    "method_uri_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo o codigo do http\n",
    "status_pattern = r'\\s(\\d{3})\\s'\n",
    "\n",
    "status = [re.search(status_pattern, item).group(1) for item in sample_logs]\n",
    "\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Unindo tudo\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "\n",
    "\n",
    "logs_df = base_df.select(regexp_extract('value', host_pattern, 1).alias('host'),\n",
    "\n",
    "                         regexp_extract('value', ts_pattern, 1).alias('timestamp'),\n",
    "\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 1).alias('method'),\n",
    "\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 2).alias('endpoint'),\n",
    "\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 3).alias('protocol'),\n",
    "\n",
    "                         regexp_extract('value', status_pattern, 1).cast('integer').alias('status'),\n",
    "\n",
    "                         regexp_extract('value', content_size_pattern, 1).cast('integer').alias('content_size'))\n",
    "\n",
    "logs_df.show(10, truncate=True)\n",
    "\n",
    "print((logs_df.count(), len(logs_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Contando os hosts unicos\n",
    "unique_host_count = (logs_df.select('host').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 - Reposta\n",
    "(base_df .filter(base_df['status'] == '404').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 - Resposta\n",
    "hosts_404_count_df = (not_found_df.groupBy(\"host\").count().sort(\"count\", ascending=False).limit(5))\n",
    "\n",
    "hosts_404_count_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_by_date_sorted_df = (not_found_df.groupBy(F.dayofmonth('time').alias('day')).count().sort(\"day\"))\n",
    "errors_by_date_sorted_pd_df = errors_by_date_sorted_df.toPandas()\n",
    "errors_by_date_sorted_pd_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
